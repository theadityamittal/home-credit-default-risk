{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nbGXPFj6QTHY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "folder_path = '/content/drive/My Drive/home-credit-default-risk'\n",
        "os.listdir(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfB1hVS8QZQj",
        "outputId": "f6366155-a4cf-41e6-840a-083512cd0086"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['HomeCredit_columns_description.csv',\n",
              " 'POS_CASH_balance.csv',\n",
              " 'application_test.csv',\n",
              " 'application_train.csv',\n",
              " 'bureau.csv',\n",
              " 'bureau_balance.csv',\n",
              " 'credit_card_balance.csv',\n",
              " 'installments_payments.csv',\n",
              " 'previous_application.csv',\n",
              " 'sample_submission.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_kg_hide-input": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false,
        "id": "o7zwsBnLazrv"
      },
      "cell_type": "code",
      "source": [
        "application_train = pd.read_csv(os.path.join(folder_path, 'application_train.csv'))\n",
        "application_test = pd.read_csv(os.path.join(folder_path, 'application_test.csv'))\n",
        "bureau = pd.read_csv(os.path.join(folder_path, 'bureau.csv'))\n",
        "bureau_balance = pd.read_csv(os.path.join(folder_path, 'bureau_balance.csv'))\n",
        "POS_CASH_balance = pd.read_csv(os.path.join(folder_path, 'POS_CASH_balance.csv'))\n",
        "credit_card_balance = pd.read_csv(os.path.join(folder_path, 'credit_card_balance.csv'))\n",
        "previous_application = pd.read_csv(os.path.join(folder_path, 'previous_application.csv'))\n",
        "installments_payments = pd.read_csv(os.path.join(folder_path, 'installments_payments.csv'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a1d86b14-dff9-4bdc-acba-f20784047f86",
        "_uuid": "e9a401e7bb0604cc2e0219f80b7ab2d47b9440bd",
        "trusted": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdbaDzEzazrv",
        "outputId": "60def375-1d32-4259-ce16-afd688769314"
      },
      "cell_type": "code",
      "source": [
        "print('Size of application_train data', application_train.shape)\n",
        "print('Size of application_test data', application_test.shape)\n",
        "print('Size of POS_CASH_balance data', POS_CASH_balance.shape)\n",
        "print('Size of bureau_balance data', bureau_balance.shape)\n",
        "print('Size of previous_application data', previous_application.shape)\n",
        "print('Size of installments_payments data', installments_payments.shape)\n",
        "print('Size of credit_card_balance data', credit_card_balance.shape)\n",
        "print('Size of bureau data', bureau.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of application_train data (307511, 122)\n",
            "Size of application_test data (48744, 121)\n",
            "Size of POS_CASH_balance data (10001358, 8)\n",
            "Size of bureau_balance data (27299925, 3)\n",
            "Size of previous_application data (1670214, 37)\n",
            "Size of installments_payments data (13605401, 8)\n",
            "Size of credit_card_balance data (3840312, 23)\n",
            "Size of bureau data (1716428, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le_count = 0\n",
        "\n",
        "# Iterate through the columns\n",
        "for col in application_train:\n",
        "    if application_train[col].dtype == 'object':\n",
        "        # If 2 or fewer unique categories\n",
        "        if len(list(application_train[col].unique())) <= 2:\n",
        "            # Train on the training data\n",
        "            le.fit(application_train[col])\n",
        "            # Transform both training and testing data\n",
        "            application_train[col] = le.transform(application_train[col])\n",
        "            application_test[col] = le.transform(application_test[col])\n",
        "\n",
        "            # Keep track of how many columns were label encoded\n",
        "            le_count += 1\n",
        "\n",
        "print('%d columns were label encoded.' % le_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY3fK7Bzfvpt",
        "outputId": "bfbca2b1-5e12-4632-a70e-e983b639d309"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 columns were label encoded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding of categorical variables\n",
        "application_train = pd.get_dummies(application_train)\n",
        "application_test = pd.get_dummies(application_test)\n",
        "\n",
        "print('Training Features shape: ', application_train.shape)\n",
        "print('Testing Features shape: ', application_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW4uFoAufyDZ",
        "outputId": "ac9cb764-8b69-40c5-db56-b2a5ef2bce05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features shape:  (307511, 243)\n",
            "Testing Features shape:  (48744, 239)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a new dataframe for polynomial features\n",
        "poly_features = application_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n",
        "poly_features_test = application_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
        "\n",
        "# Import SimpleImputer for handling missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Separate the target variable\n",
        "poly_target = poly_features['TARGET']\n",
        "\n",
        "# Drop the target column from the feature set\n",
        "poly_features = poly_features.drop(columns=['TARGET'])\n",
        "\n",
        "# Impute missing values\n",
        "poly_features = imputer.fit_transform(poly_features)\n",
        "poly_features_test = imputer.transform(poly_features_test)\n",
        "\n",
        "# Import PolynomialFeatures and create the polynomial object\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_transformer = PolynomialFeatures(degree=3)"
      ],
      "metadata": {
        "id": "dHs3Lxvycq4x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the polynomial features\n",
        "poly_transformer.fit(poly_features)\n",
        "\n",
        "# Transform the features\n",
        "poly_features = poly_transformer.transform(poly_features)\n",
        "poly_features_test = poly_transformer.transform(poly_features_test)\n",
        "print('Polynomial Features shape: ', poly_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m7vO1hec1BE",
        "outputId": "e81761dd-7e6c-47cd-b6c4-2e681435b857"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Features shape:  (307511, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the feature names for the polynomial features\n",
        "feature_names = poly_transformer.get_feature_names_out(input_features=['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])\n",
        "\n",
        "# Display the first 15 feature names\n",
        "print(feature_names[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLVIp8Ofc1HU",
        "outputId": "c961cbcb-a8f7-4c65-9695-80396f2d820d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1' 'EXT_SOURCE_1' 'EXT_SOURCE_2' 'EXT_SOURCE_3' 'DAYS_BIRTH'\n",
            " 'EXT_SOURCE_1^2' 'EXT_SOURCE_1 EXT_SOURCE_2' 'EXT_SOURCE_1 EXT_SOURCE_3'\n",
            " 'EXT_SOURCE_1 DAYS_BIRTH' 'EXT_SOURCE_2^2' 'EXT_SOURCE_2 EXT_SOURCE_3'\n",
            " 'EXT_SOURCE_2 DAYS_BIRTH' 'EXT_SOURCE_3^2' 'EXT_SOURCE_3 DAYS_BIRTH'\n",
            " 'DAYS_BIRTH^2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app_train_domain = application_train.copy()\n",
        "app_test_domain = application_test.copy()\n",
        "\n",
        "app_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\n",
        "app_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\n",
        "app_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
        "app_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']"
      ],
      "metadata": {
        "id": "_bQ1p27Qc1LP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\n",
        "app_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\n",
        "app_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
        "app_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']"
      ],
      "metadata": {
        "id": "uZWaKSQNfOwo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eTsii9n9hYB6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = application_train['TARGET']\n",
        "\n",
        "# Align the training and testing data, keep only columns present in both dataframes\n",
        "application_train, application_test = application_train.align(application_test, join = 'inner', axis = 1)\n",
        "\n",
        "# Add the target back in\n",
        "application_train['TARGET'] = train_labels\n",
        "\n",
        "print('Training Features shape: ', application_train.shape)\n",
        "print('Testing Features shape: ', application_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tFTD-IPdBlV",
        "outputId": "e9cf27dd-ddd3-4eec-8210-cf49b12443db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features shape:  (307511, 240)\n",
            "Testing Features shape:  (48744, 239)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Dropping the target from the training data\n",
        "if 'TARGET' in application_train:\n",
        "    train = application_train.drop(columns=['TARGET'])\n",
        "else:\n",
        "    train = application_train.copy()\n",
        "\n",
        "# Feature names\n",
        "features = list(train.columns)\n",
        "\n",
        "# Copy of the testing data\n",
        "test = application_test.copy()\n",
        "\n",
        "# Median imputation of missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Scale each feature to 0-1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Fit on the training data\n",
        "imputer.fit(train)\n",
        "\n",
        "# Transform both training and testing data\n",
        "train = imputer.transform(train)\n",
        "test = imputer.transform(test)\n",
        "\n",
        "# Repeat with the scaler\n",
        "scaler.fit(train)\n",
        "train = scaler.transform(train)\n",
        "test = scaler.transform(test)\n",
        "\n",
        "print('Training data shape: ', train.shape)\n",
        "print('Testing data shape: ', test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBqpZ0FLarxb",
        "outputId": "936195e4-3e2b-4e3e-9c5a-9a95c9e3e59f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape:  (307511, 239)\n",
            "Testing data shape:  (48744, 239)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Ensure train_labels is aligned with the processed train data\n",
        "train_labels = application_train['TARGET']\n",
        "\n",
        "# Randomly sample 100,000 rows from the training dataset\n",
        "sampled_indices = pd.Series(range(train.shape[0])).sample(n=10000, random_state=42)\n",
        "train_sampled = train[sampled_indices]\n",
        "labels_sampled = train_labels.iloc[sampled_indices]\n",
        "\n",
        "# Perform an 80-20 split on the sampled data\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_sampled, labels_sampled, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Sampled Training Data Shape: \", X_train.shape)\n",
        "print(\"Sampled Validation Data Shape: \", X_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBG8-qJv0eYy",
        "outputId": "e1c13d8e-1ba2-4850-df45-6205c8192c4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled Training Data Shape:  (8000, 239)\n",
            "Sampled Validation Data Shape:  (2000, 239)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline Model AUC Scores**"
      ],
      "metadata": {
        "id": "mNyUqEU7luuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Logistic Regression"
      ],
      "metadata": {
        "id": "vP2e0tyumKSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# Train the logistic regression model on the training split\n",
        "log_reg = LogisticRegression(C=1)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the validation set\n",
        "y_valid_pred = log_reg.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Calculate AUC on the validation set\n",
        "auc = roc_auc_score(y_valid, y_valid_pred)\n",
        "print(f'Validation AUC: {auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOVII6ATcVa6",
        "outputId": "6bed6017-a667-40cd-f9e8-7a8d9222096a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.7339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Logistic Regression with Lasso (L1) Regularization"
      ],
      "metadata": {
        "id": "ZV8nqmxJo5vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with Lasso (L1 Regularization)\n",
        "lasso_model = LogisticRegression(penalty='l1', C=1.0, solver='liblinear', random_state=42)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "lasso_predictions = lasso_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Calculate AUC\n",
        "lasso_auc = roc_auc_score(y_valid, lasso_predictions)\n",
        "print(f'Lasso Logistic Regression AUC: {lasso_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXnzeymOpCMt",
        "outputId": "8951f127-4b90-4f52-e4d9-cf2da97758f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Logistic Regression AUC: 0.7348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Logistic Regression with Ridge (L2) Regularization"
      ],
      "metadata": {
        "id": "3GH6dLYZp9zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with Ridge (L2 Regularization)\n",
        "ridge_model = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', random_state=42)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "ridge_predictions = ridge_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Calculate AUC\n",
        "ridge_auc = roc_auc_score(y_valid, ridge_predictions)\n",
        "print(f'Ridge Logistic Regression AUC: {ridge_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO6i1y-BqDQc",
        "outputId": "5c5590fb-72e4-44d0-d7be-5e1130dd8709"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Logistic Regression AUC: 0.7336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Random Forest"
      ],
      "metadata": {
        "id": "ehCNpSusmOYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Create the Random Forest model\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=50, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Train on the training split\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the validation set\n",
        "y_valid_pred = random_forest.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Calculate AUC on the validation set\n",
        "auc = roc_auc_score(y_valid, y_valid_pred)\n",
        "print(f'\\nValidation AUC: {auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNAvU4bCiESE",
        "outputId": "f8c9b755-b518-410b-8837-afcb58c40642"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation AUC: 0.6770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500, 1000],       # Number of trees\n",
        "    'max_depth': [10, 20, 30, None],            # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],            # Minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],              # Minimum samples required at each leaf node\n",
        "    'max_features': ['sqrt', 'log2', None]      # Number of features to consider when looking for the best split\n",
        "}\n",
        "\n",
        "# Randomized search with 3-fold cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=50, n_jobs=-1),\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,             # Number of parameter combinations to try\n",
        "    cv=3,                  # 3-fold cross-validation\n",
        "    scoring='roc_auc',     # Use AUC as the scoring metric\n",
        "    random_state=42,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and AUC\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n",
        "print(f'Best AUC from cross-validation: {random_search.best_score_:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-m0G4RQLAr-",
        "outputId": "fb681d53-fa8c-4ab0-82ab-1209f73f89f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "Best Parameters: {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
            "Best AUC from cross-validation: 0.6928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Predict probabilities on the validation set\n",
        "y_valid_pred = best_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Calculate AUC on the validation set\n",
        "auc = roc_auc_score(y_valid, y_valid_pred)\n",
        "print(f'Validation AUC with the best model: {auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urKWUbNRLUnj",
        "outputId": "3ff11b35-51da-4526-f4f2-b325fb635c52"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC with the best model: 0.7239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. SVM"
      ],
      "metadata": {
        "id": "QCfcBhJlqdlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "# Create the SVM model with probability outputs enabled\n",
        "svm_model = SVC(kernel='rbf', probability=True, random_state=42)  # RBF kernel for non-linear SVM\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the validation set\n",
        "svm_predictions = svm_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Calculate AUC\n",
        "svm_auc = roc_auc_score(y_valid, svm_predictions)\n",
        "print(f'SVM AUC: {svm_auc:.4f}')"
      ],
      "metadata": {
        "id": "V73GeP43nSaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7236829b-095e-4202-fa26-c962ad415068"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM AUC: 0.6677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [0.01, 0.1, 1, 10],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "# Create the SVM model\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Randomized search with 3-fold cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=svm,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=10,               # Number of parameter combinations to try\n",
        "    scoring='roc_auc',       # Use AUC as the scoring metric\n",
        "    cv=3,                    # 3-fold cross-validation\n",
        "    random_state=42,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and AUC\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oS93HjdVrZA",
        "outputId": "a6eeab0f-ccbd-4c86-c099-0e4a6cebb118"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Best Parameters: {'kernel': 'rbf', 'gamma': 0.1, 'C': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation set\n",
        "best_model = random_search.best_estimator_\n",
        "svm_predictions = best_model.predict_proba(X_valid)[:, 1]\n",
        "svm_auc = roc_auc_score(y_valid, svm_predictions)\n",
        "print(f'Validation AUC with the best model: {svm_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3-7QZdRV_fj",
        "outputId": "6dc63ec9-dc2b-4506-e756-f00e1d740a37"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC with the best model: 0.6735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "7KJd6TtClCyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Create the XGBoost model\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the validation set\n",
        "xgb_predictions = xgb_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Calculate AUC\n",
        "xgb_auc = roc_auc_score(y_valid, xgb_predictions)\n",
        "print(f'XGBoost AUC: {xgb_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTWVwENiX7jg",
        "outputId": "95a23fad-e96f-4792-ef9b-79b6848e5c91"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [04:03:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost AUC: 0.6740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'reg_alpha': [0, 0.1, 1],\n",
        "    'reg_lambda': [1, 1.5, 2]\n",
        "}\n",
        "\n",
        "# Randomized search with 3-fold cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42),\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,  # Number of parameter combinations to try\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and AUC\n",
        "print(f'Best Parameters: {random_search.best_params_}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJSOmS5R26OQ",
        "outputId": "198ae52f-9ec9-4641-8ecd-e00b7fa4c2c0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [04:04:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'subsample': 0.6, 'reg_lambda': 2, 'reg_alpha': 0.1, 'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model on the validation set\n",
        "best_model = random_search.best_estimator_\n",
        "xgb_predictions = best_model.predict_proba(X_valid)[:, 1]\n",
        "xgb_auc = roc_auc_score(y_valid, xgb_predictions)\n",
        "print(f'Validation AUC with the best model: {xgb_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciejdxf029h-",
        "outputId": "2806c711-859d-4db6-f18c-90401711d117"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC with the best model: 0.7334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost"
      ],
      "metadata": {
        "id": "6C0Xchb0soSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create the AdaBoost model with a Decision Tree base estimator\n",
        "estimator = DecisionTreeClassifier(max_depth=1, random_state=42)  # Weak learner\n",
        "adaboost_model = AdaBoostClassifier(estimator=estimator, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the validation set\n",
        "adaboost_predictions = adaboost_model.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "# Calculate AUC\n",
        "adaboost_auc = roc_auc_score(y_valid, adaboost_predictions)\n",
        "print(f'AdaBoost AUC: {adaboost_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCyhQJbvs-ss",
        "outputId": "1c048273-dc3c-4c74-e315-efe0cb683725"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost AUC: 0.7004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grid for AdaBoost\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 500],  # Number of boosting rounds\n",
        "    'learning_rate': [0.01, 0.1, 0.5, 1.0],  # Shrinks contribution of each base estimator\n",
        "    'estimator__max_depth': [1, 2, 3]  # Depth of the decision tree (weak learner)\n",
        "}\n",
        "\n",
        "# Randomized search with 3-fold cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=42), random_state=42),\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=20,  # Number of parameter combinations to try\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(f'Best Parameters: {random_search.best_params_}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoS22iyetMpG",
        "outputId": "6f8f90c8-ea23-449b-af0c-b71908bb40e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_estimators': 50, 'learning_rate': 0.1, 'estimator__max_depth': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model on the validation set\n",
        "best_model = random_search.best_estimator_\n",
        "adaboost_predictions = best_model.predict_proba(X_valid)[:, 1]\n",
        "adaboost_auc = roc_auc_score(y_valid, adaboost_predictions)\n",
        "print(f'Validation AUC with the best model: {adaboost_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvp_CFDTteqN",
        "outputId": "52f322c6-2385-40fe-c620-84f646154451"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC with the best model: 0.7310\n"
          ]
        }
      ]
    }
  ]
}